<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="ray">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/17/leetcode1734/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ray">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/17/leetcode1734/" class="post-title-link" itemprop="url">leetcode 1734</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-05-17 14:08:39 / Modified: 15:41:21" itemprop="dateCreated datePublished" datetime="2021-05-17T14:08:39+08:00">2021-05-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="leetcode-1734"><a href="#leetcode-1734" class="headerlink" title="leetcode 1734"></a>leetcode 1734</h1><h2 id="涉及知识点"><a href="#涉及知识点" class="headerlink" title="涉及知识点"></a>涉及知识点</h2><p>亦或运算 XOR，题目理解</p>
<h2 id="答案"><a href="#答案" class="headerlink" title="答案"></a>答案</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public int[] decode(int[] encoded) &#123;</span><br><span class="line">        int num &#x3D;0;</span><br><span class="line">        int[] nums &#x3D; new int[encoded.length+1];</span><br><span class="line">        for(int i &#x3D; 1;i&lt;nums.length+1;i++)&#123;</span><br><span class="line">            num^&#x3D;i;</span><br><span class="line">        &#125;</span><br><span class="line">        int count &#x3D; 0;</span><br><span class="line">        for(int j &#x3D; 1;j&lt;encoded.length;j+&#x3D;2)&#123;</span><br><span class="line">            count ^&#x3D;encoded[j];</span><br><span class="line">        &#125;</span><br><span class="line">        nums[0] &#x3D; num^count;</span><br><span class="line">        for(int i &#x3D;1;i&lt;encoded.length+1;i++)&#123;</span><br><span class="line">            nums[i]&#x3D; encoded[i-1]^nums[i-1]; </span><br><span class="line">        &#125;</span><br><span class="line">        return nums;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><h3 id="题干"><a href="#题干" class="headerlink" title="题干"></a>题干</h3><p>给你一个整数数组 perm ，它是前 n 个正整数的排列，且 n 是个 奇数 。<br>它被加密成另一个长度为 n - 1 的整数数组 encoded ，满足 encoded[i] = perm[i] XOR perm[i + 1] 。比方说，如果 perm = [1,3,2] ，那么 encoded = [2,1] 。<br>给你 encoded 数组，请你返回原始数组 perm 。题目保证答案存在且唯一。</p>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>题目有个关键点在于这句: 整数数组 perm ，它是前 n 个正整数的排列。这句话的意思是，这个数组，里面的元素一定是从1到n，但是可能全排列中的一种。比如 n = 5，数组perm可能是[1,2,3,4,5], 或者 [4,5,3,1,2] 等。<br>以及，XOR的性质</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A xor B &#x3D; C </span><br><span class="line">得到</span><br><span class="line">A XOR A XOR B &#x3D; C XOR A </span><br><span class="line">得到 </span><br><span class="line">B &#x3D; C XOR A</span><br></pre></td></tr></table></figure>
<h3 id="解题"><a href="#解题" class="headerlink" title="解题"></a>解题</h3><p>原数组 list = [$a_1$,$a_2$,$a_3$,$a_4$,$a_5$]<br>加密list encoded = [$a_1$ XOR $a_2$^[x1],$a_2$ XOR $a_3$^[x2],$a_3$ XOR $a_4$^[x3],$a_4$ XOR $a_5$^[x4]]</p>
<p>$a_1$ XOR $a_1$ = $x_1$ =&gt; $a_2$ = $a_1$ XOR $x_1$<br>$a_2$ XOR $a_3$ = $x_2$ =&gt; $a_3$ = $a_2$ XOR $x_2$<br>.<br>.<br>.<br>所以:<br>$a_n$ = $a_{n-1}$ XOR $x_{n-1}$<br>在所有$x_{n1}$ 已经确立的情况下，我们只需要知道$a_1$就可以推出所有的序列<br>而：<br>由于perm是前n个数的全排列，我们可以通过以下代码获得</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n &#x3D; 1</span><br><span class="line">for i in range(1,n + 1):</span><br><span class="line">    n ^&#x3D; i</span><br></pre></td></tr></table></figure>
<p>而<br>n = $a_1$ XOR $a_2$ XOR $a_3$ XOR $a_4$ XOR $a_5$<br>  = $a_1$ XOR ($a_2$ XOR $a_3$) xor ($a_4$ XOR $a_5$)<br>  = $a_1$ XOR $x_2$ XOR $x_4$</p>
<p>所以<br>$a_1$ = n xor $x_{i}$ 且i 为 偶数</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/17/leetcode232/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ray">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/17/leetcode232/" class="post-title-link" itemprop="url">leetcode 232</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-05-17 13:08:39 / Modified: 15:37:25" itemprop="dateCreated datePublished" datetime="2021-05-17T13:08:39+08:00">2021-05-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="leetcode-232"><a href="#leetcode-232" class="headerlink" title="leetcode 232"></a>leetcode 232</h1><h2 id="涉及知识点"><a href="#涉及知识点" class="headerlink" title="涉及知识点"></a>涉及知识点</h2><p>动态规划</p>
<h2 id="答案"><a href="#答案" class="headerlink" title="答案"></a>答案</h2><p>Java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Solution&#123;</span><br><span class="line">    public int numWays(int steps, int arrLen)&#123;</span><br><span class="line">        final int mod &#x3D; 1000000007;</span><br><span class="line">        int maxColumn &#x3D;Math.min(arrLen-1, steps);</span><br><span class="line">        int [][]dp &#x3D; new int[steps + 1][maxColumn + 1];</span><br><span class="line">        dp[0][0] &#x3D; 1;</span><br><span class="line">        for(int i &#x3D; 1;i &lt;&#x3D; steps;i++)&#123;</span><br><span class="line">            for(int j &#x3D; 0;j &lt;&#x3D; maxColumn;j++)&#123;</span><br><span class="line">                dp[i][j] &#x3D; dp[i-1][j];</span><br><span class="line">                if (j -1 &gt;&#x3D; 0)&#123;</span><br><span class="line">                    dp[i][j] &#x3D; (dp[i][j] + dp[i-1][j-1]) % mod;</span><br><span class="line">                &#125;</span><br><span class="line">                if (j + 1 &lt;&#x3D; maxColumn)&#123;</span><br><span class="line">                    dp[i][j] &#x3D; (dp[i][j] + dp[i-1][j+1]) % mod;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; </span><br><span class="line">        return dp[steps][0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><h3 id="动态规划简介"><a href="#动态规划简介" class="headerlink" title="动态规划简介"></a>动态规划简介</h3><p>动态规划的核心是 - 找出状态转移方程<br>一例:<br><img src="/2021/05/17/leetcode232/matrix.PNG" alt="matrix"><br>从起点，到终点，求最小权重的路径。这里状态转移方程就是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">min_weight(i,j)  &#x3D; d[i][j] + min(d[i-1][j],d[i][j-1])</span><br></pre></td></tr></table></figure>
<h3 id="题目的分析"><a href="#题目的分析" class="headerlink" title="题目的分析"></a>题目的分析</h3><h4 id="题干"><a href="#题干" class="headerlink" title="题干"></a>题干</h4><p>有一个长度为 arrLen 的数组，开始有一个指针在索引 0 处。<br>每一步操作中，你可以将指针向左或向右移动 1 步，或者停在原地（指针不能被移动到数组范围外）。<br>给你两个整数 steps 和 arrLen ，请你计算并返回：在恰好执行 steps 次操作以后，指针仍然指向索引 0 处的方案数。<br>由于答案可能会很大，请返回方案数 模 10^9 + 7(1000000007) 后的结果。</p>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>设计状态转移方程 d[i][j],i 代表steps，j代表索引的位置，value代表可有的方法数目，比如: d[0][0] = 1，就代表在 step 0 时刻，指针在index 为 0 的位置。只有 1 种方法。<br>这里： i和j的范围明显大于0，i小于等于steps。j索引的位置应该小于数组的长度或者是steps的长度，所以</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0 &lt;&#x3D; i &lt;&#x3D; steps</span><br><span class="line">0 &lt;&#x3D; j &lt;&#x3D; min(steps, arrLen)</span><br></pre></td></tr></table></figure>
<p>状态方程d[i][j]的数据来自于3种路径，分别是：   </p>
<ol>
<li>从左到右: d[i-1][j-1]   </li>
<li>从右到左: d[i-1][j+1]   </li>
<li>不动: d[i-1][j-1]   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for(int i &#x3D; 1;i &lt;&#x3D; steps;i++)&#123;</span><br><span class="line">   for(int j &#x3D; 0;j &lt;&#x3D; maxColumn;j++)&#123;</span><br><span class="line">       dp[i][j] &#x3D; dp[i-1][j]; &#x2F;&#x2F; 这里代表不动的情况</span><br><span class="line">   &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br></pre></td></tr></table></figure>
且要保证，j不会越界，也就是不会小于0, 或者大于min(steps, arrLen)<br>那么状态转移的过程就是  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">for(int i &#x3D; 1;i &lt;&#x3D; steps;i++)&#123;</span><br><span class="line">   for(int j &#x3D; 0;j &lt;&#x3D; maxColumn;j++)&#123;</span><br><span class="line">       dp[i][j] &#x3D; dp[i-1][j]; &#x2F;&#x2F; 这里代表不动的情况</span><br><span class="line">       if (j -1 &gt;&#x3D; 0)&#123;        &#x2F;&#x2F; 防止指针左移小于index 0</span><br><span class="line">           dp[i][j] &#x3D; (dp[i][j] + dp[i-1][j-1]) % mod;</span><br><span class="line">       &#125;</span><br><span class="line">       if (j + 1 &lt;&#x3D; maxColumn)&#123; &#x2F;&#x2F; 防止指针右移大于 maxColumn,也就是超过steps或者数组长度</span><br><span class="line">           dp[i][j] &#x3D; (dp[i][j] + dp[i-1][j+1]) % mod;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/10/spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ray">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/10/spark/" class="post-title-link" itemprop="url">spark</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-05-10 14:08:39" itemprop="dateCreated datePublished" datetime="2021-05-10T14:08:39+08:00">2021-05-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-05-17 15:48:52" itemprop="dateModified" datetime="2021-05-17T15:48:52+08:00">2021-05-17</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Spark-简介"><a href="#Spark-简介" class="headerlink" title="Spark 简介"></a>Spark 简介</h1><h2 id="Spark-what"><a href="#Spark-what" class="headerlink" title="Spark, what?"></a>Spark, what?</h2><p>Spark 是一个用于大数据的分布式计算框架</p>
<h2 id="Why-the-spark"><a href="#Why-the-spark" class="headerlink" title="Why the spark"></a>Why the spark</h2><p>首先，MapReduce 可以处理 one-pass 计算，但是更加复杂的就不行，比如图计算，机器学习。交互性更强的ad-hoc queries，也不能做到。还有像流数据的处理，也不可能。</p>
<h2 id="Spark-的结构和成员"><a href="#Spark-的结构和成员" class="headerlink" title="Spark 的结构和成员"></a>Spark 的结构和成员</h2><ul>
<li>Master node</li>
<li>Cluster Manager</li>
<li>Worker Node<br><img src="/2021/05/10/spark/spark-a.PNG" alt="spark-a"></li>
</ul>
<h2 id="Resilient-Distributed-Dataset-RDD"><a href="#Resilient-Distributed-Dataset-RDD" class="headerlink" title="Resilient Distributed Dataset (RDD)"></a>Resilient Distributed Dataset (RDD)</h2><ul>
<li>RDD 是存数据的位置</li>
<li>spark中的基础数据类型<ol>
<li>并行(parallel)</li>
<li>容错(resilient)</li>
</ol>
</li>
</ul>
<h3 id="RDD-特点"><a href="#RDD-特点" class="headerlink" title="RDD 特点"></a>RDD 特点</h3><ul>
<li>在内存中计算(In memory computation)</li>
<li>分区(Partitioning)</li>
<li>容错(Fault tolerance)</li>
<li>不可变(Immutability)</li>
<li>持久性(Persistence)</li>
<li>Coarse-grained operations</li>
<li>Location-stickiness</li>
</ul>
<h3 id="RDD-创建-Creation"><a href="#RDD-创建-Creation" class="headerlink" title="RDD 创建(Creation)"></a>RDD 创建(Creation)</h3><ul>
<li>在driver program中，并行已在的集合</li>
<li>引用外部存储的数据,像HDFS,HBASE,默认下，spark对每个block中的文件做一个partition</li>
</ul>
<h3 id="RDD-算子-Operation"><a href="#RDD-算子-Operation" class="headerlink" title="RDD 算子(Operation)"></a>RDD 算子(Operation)</h3><h4 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h4><p>function, 一个rdd进，一到多个rdd出。不会触发计算。</p>
<h5 id="宽窄依赖-Narrow-and-wide-Transformations"><a href="#宽窄依赖-Narrow-and-wide-Transformations" class="headerlink" title="宽窄依赖( Narrow and wide Transformations)"></a>宽窄依赖( Narrow and wide Transformations)</h5><p>narrow没有shuffle, 操作: map,flatMap,filter,sample<br>wide有shuffle,比如softByKey, reduceByKey,groupByKey,join<br><img src="/2021/05/10/spark/narrow-wude.PNG" alt="narrow-wide"></p>
<h4 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h4><p>rdd的算子，输出是非rdd的value.会触发spark的计算.<br>以下都是action的算子: collect,take,reduce,forEach,sample,count,save   </p>
<h2 id="惰性计算-lazy-Evaluation"><a href="#惰性计算-lazy-Evaluation" class="headerlink" title="惰性计算(lazy Evaluation)"></a>惰性计算(lazy Evaluation)</h2><p>目的就是最小化计算机的工作，也就是延迟求值或者最小化求值。除了提升性能外，还可以构造一个无限的数据模型<br>eg:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">li &#x3D; [lambda :x for x in range(10)]</span><br><span class="line">res &#x3D; li[0]()</span><br><span class="line">print(res)</span><br><span class="line">#输出：9</span><br></pre></td></tr></table></figure>
<p>原因: 由于编程语言延迟求值的特性，在使用延迟求值的时候，表达式不在它被绑定到变量之后就立即求值，而是在该值被取用的时候求值，<br>当调用li<a href>0</a> 函数时，x的值已经是9了，所以输出的是9<br>怎么改成从0到9呢？   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">li2 &#x3D; [lambda x&#x3D;x:x for x in range(10)]</span><br><span class="line">res &#x3D; li2[0]()</span><br><span class="line"></span><br><span class="line">print(res)</span><br><span class="line">for i in li2:</span><br><span class="line">    print(i(), end&#x3D;&quot; &quot;)</span><br></pre></td></tr></table></figure>

<h2 id="共享变量-shared-variable"><a href="#共享变量-shared-variable" class="headerlink" title="共享变量(shared variable)"></a>共享变量(shared variable)</h2><h3 id="广播变量-broadcast-variable"><a href="#广播变量-broadcast-variable" class="headerlink" title="广播变量 (broadcast variable)"></a>广播变量 (broadcast variable)</h3><p>广播变量类似MapReduce中的DistributeFile, 通常是一个小表。在drive中创建，一旦创建后，表会在整个集群中广播，能让所有正在运行的计算任务以只读的方式访问。支持各种数据类型。   </p>
<h4 id="广播变量在spark中的传播方法"><a href="#广播变量在spark中的传播方法" class="headerlink" title="广播变量在spark中的传播方法"></a>广播变量在spark中的传播方法</h4><p>为了保证所有的节点都能接受到driver的变量，我们不能直接去连接driver，这会导致driver会负载，这里，executor 使用的是http连接去拉取数据，类似点对点传输。<br>Spark中，driver会将已序列化的数据分成小块，然后再将数据存储在自己的blockmanager中，当executor开始运行的时候，每个executor首先从自己的内部块管理器中取得广播变量。如果以前广播过，那么直接取。假如没有，executor会从driver或者其他的executor中拉数据块。一旦拉到数据块，就会放到自己的blockmanager中。供自己和其他拉取的executor使用。这样，就很好防止的driver单点的问题。<br><img src="/2021/05/10/spark/boardcast.PNG" alt="boardcast"></p>
<h4 id="广播变量的优点"><a href="#广播变量的优点" class="headerlink" title="广播变量的优点"></a>广播变量的优点</h4><p>一定数据量范围内，避免shuffle，使得计算尽可能的本地运行。Spark的Map端的操作，就是用广播变量来实现的</p>
<h3 id="累加器-Accumulator"><a href="#累加器-Accumulator" class="headerlink" title="累加器(Accumulator)"></a>累加器(Accumulator)</h3><p>一个只能累加的共享变量，初始化的累加器的变量是0，在被action算子触发计算后，累加器在map函数中调用，然后会累加，内置的累加器有：</p>
<ul>
<li>LongAccumulator: 长整型累加器，64位整数。用于求和，计数，求均值。</li>
<li>DoubleAccumulator: 双精度累加器，双精度浮点数。用于求和，计数，求均值。</li>
<li>CollectionAccumulator[T]: 集合型累加器，可以用来收集所需信息的集合。<br>以上三种都继承自：AccumulatorV2,此外，仍然可以自定义累加器。</li>
</ul>
<h4 id="RDD-血统-Lineage"><a href="#RDD-血统-Lineage" class="headerlink" title="RDD 血统(Lineage)"></a>RDD 血统(Lineage)</h4><p>RDD的依赖图(dependency graph),记录所有rdd的依赖关系<br>Node: RDDs<br>Edges: 依赖关系</p>
<h4 id="容错（Fault-tolerance）"><a href="#容错（Fault-tolerance）" class="headerlink" title="容错（Fault tolerance）"></a>容错（Fault tolerance）</h4><p>当worker fail的时候，rdd的所有分区都会丢。<br>但是通过Lineage，我们可以重新得到rdd.同时，这部分的task，会被分配给其他的worker  </p>
<h3 id="DAG-in-Spark"><a href="#DAG-in-Spark" class="headerlink" title="DAG in Spark"></a>DAG in Spark</h3><p>Direct graph with no cycle   </p>
<ul>
<li>Node: RDD, result   </li>
<li>Edge: RDD 之间的Operations<br>在Action的阶段，DAG会被submit到DAG Scheduler上。之后会被进一步分解成task. DAG也能比mapreduce做更好的全局优化<h4 id="Stages-and-Tasks"><a href="#Stages-and-Tasks" class="headerlink" title="Stages and Tasks"></a>Stages and Tasks</h4>DAG Scheduler 会把图分解成多个stages, stages的生成是基于算子。<br>窄依赖会被合并到一个stages里面，宽依赖会分割成两个stages.这些stages会被submit到task scheduler.<br>task的数量取决于partition的数量。没有依赖关系的stages可以被集群并行处理   <h4 id="Lineage-vs-DAG-in-Spark"><a href="#Lineage-vs-DAG-in-Spark" class="headerlink" title="Lineage vs. DAG in Spark"></a>Lineage vs. DAG in Spark</h4></li>
<li>相同的数据结构（都是图）</li>
<li>不同的end nodes</li>
<li>Spark里面的role不同</li>
</ul>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="MapReduce-中的数据结构"><a href="#MapReduce-中的数据结构" class="headerlink" title="MapReduce 中的数据结构"></a>MapReduce 中的数据结构</h2><p>key-value pairs，key和value可以是任意的数据结构<br>MapReduce的算法，可以用被apply再任意的数据上，比如 网页的collection,key就是urls,value就可以是HTML.</p>
<h2 id="Map-and-Reduce"><a href="#Map-and-Reduce" class="headerlink" title="Map and Reduce"></a>Map and Reduce</h2><ul>
<li>Map<ol>
<li>读数据(RDD in Spark)</li>
<li>会产生key-value pairs的中间数据</li>
</ol>
</li>
<li>Reduce<ol>
<li>从先前的多个map的jobs中，接受key-value的pairs</li>
<li>聚合中间数据，到最终结果</li>
</ol>
</li>
</ul>
<h2 id="Hadoop中的-mapreduce"><a href="#Hadoop中的-mapreduce" class="headerlink" title="Hadoop中的 mapreduce"></a>Hadoop中的 mapreduce</h2><ul>
<li><p>数据存储在HDFS上（以blocks的方式存储）</p>
</li>
<li><p>Hadoop中，mapreduce会把数据分割成fix-size的小数据，然后，为每个小数据生成一个map task. Map task, 会为小数据跑user-defined map function.</p>
</li>
<li><p>小数据的size，通常都是HDFS的block的size</p>
</li>
<li><p>Data locality optimization</p>
<ul>
<li>当数据在HDFS上，map task在node上跑。这也是小数据的size，和hdfs的size一样。<br>  • The largest size of the input that can be guaranteed to be stored on a single<br>  node<br>  • If the split spanned two blocks, it would be unlikely that any HDFS node<br>  stored both block</li>
</ul>
</li>
<li><p>Map的task会把结果写到local disk上(不是hdfs)</p>
<ol>
<li>Map 的结果是中间结果</li>
<li>一旦job完成，map的结果就可以直接抛弃</li>
<li>假如中间结果存在hdfs上(会有replication)，可能会导致过载(overkill)</li>
<li>假如当前Node的map task fails, hadoop会自动把map task转移到其他节点</li>
</ol>
</li>
<li><p>Reduce 的task，没有局部数据的优势</p>
<ol>
<li>通常来说，all map的task的结果，都会被合到一个reduce的task</li>
<li>reduce的结果会被保存在hdfs上以保证数据的可靠性</li>
<li>reduce的task的结果，不由input的size决定。而是单独的设定</li>
</ol>
</li>
</ul>
<p>再细节点：<br>当我们有多个reducers时，map task需要partition他们的结果</p>
<ul>
<li>一个reduce task一个partition</li>
<li>一个中间结果的key都再一个partition里面</li>
<li>partition的过程，可以再user-defined paritioning function中设定</li>
</ul>
<p><img src="/2021/05/10/spark/hadoop-partition.PNG" alt="hadoop-partition"></p>
<h2 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h2><p>shuffle 是数据重分布的过程</p>
<ul>
<li>确保每个reducer得到同个key的所有相关values</li>
<li>需要grouping</li>
</ul>
<p>Tips： Spark 和 hadoop 用的是不同的方法来shuffle</p>
<h3 id="Hadoop-中的shuffle（由framework处理）"><a href="#Hadoop-中的shuffle（由framework处理）" class="headerlink" title="Hadoop 中的shuffle（由framework处理）"></a>Hadoop 中的shuffle（由framework处理）</h3><ul>
<li>发生在每个map 和 reduce的阶段</li>
<li>使用shuffle和sort机制： Map的结果，按照key排序，发生在map结束后，开始排序</li>
<li>用combiner 去减少数据的shuffle<ol>
<li>Combiner 可以按照key来combine 所有的 key-value的对(pairs)</li>
<li>combiner不是由framework来处理<br>例子：hadoop中wordcount的过程<br><img src="/2021/05/10/spark/hadoop-wordcount.PNG" alt="hadoop-wordcount"></li>
</ol>
</li>
</ul>
<h3 id="Spark中的shuffle"><a href="#Spark中的shuffle" class="headerlink" title="Spark中的shuffle"></a>Spark中的shuffle</h3><p>（<a target="_blank" rel="noopener" href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=71#/detail/pc?id=1982%EF%BC%89">https://kaiwu.lagou.com/course/courseInfo.htm?courseId=71#/detail/pc?id=1982）</a></p>
<ul>
<li>shuffle是由某些算子触发: Distinct, join, repartition, all *By, *ByKey, 在stages直接发生<h4 id="Hash-Shuffle"><a href="#Hash-Shuffle" class="headerlink" title="Hash Shuffle"></a>Hash Shuffle</h4></li>
<li>map端发生，数据被hash partitioned</li>
<li>产生的文件被用来存储partition data的部分数据<ol>
<li>“# of mappers X # of reducers</li>
</ol>
</li>
<li>通过合并文件，来减少block的文件数量 <ul>
<li> From M * R =&gt; E*C/T * R<h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5>快，而且没有爆内存<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5>output文件量大，尤其是block的partition很多的时候<h4 id="Sort-Shuffle"><a href="#Sort-Shuffle" class="headerlink" title="Sort Shuffle"></a>Sort Shuffle</h4></li>
</ul>
</li>
<li>每个mapper 到文件， 用key来对数据排序。对每个chunk,标序</li>
<li>当map被reducer读取的时候即时合并</li>
<li>如果partition很小的话，会退化成hash shuffle<br>优点： 创建的文件小<br>缺点： 排序没有hash的速度快<h4 id="Tungsten-shuffle-sort"><a href="#Tungsten-shuffle-sort" class="headerlink" title="Tungsten shuffle-sort"></a>Tungsten shuffle-sort</h4>• More on <a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/SPARK-708">https://issues.apache.org/jira/browse/SPARK-708</a><h2 id="Spark中的-mapreduce"><a href="#Spark中的-mapreduce" class="headerlink" title="Spark中的 mapreduce"></a>Spark中的 mapreduce</h2>spark中的算子（operation）分为 transformation 和 action.<h3 id="核心rdd算子-CombineByKey"><a href="#核心rdd算子-CombineByKey" class="headerlink" title="核心rdd算子 CombineByKey"></a>核心rdd算子 CombineByKey</h3></li>
<li>作用：RDD([k,v]) =&gt; RDD([k,c]), k: key; v: value; c:combined type </li>
<li>Core: <ol>
<li>createCombiner </li>
<li>mergeValue</li>
<li>mergeCombiners</li>
</ol>
</li>
<li>eg： <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.RDD.combineByKey.html">https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.RDD.combineByKey.html</a></li>
</ul>
<h4 id="createCombiner"><a href="#createCombiner" class="headerlink" title="createCombiner"></a>createCombiner</h4><p>V =&gt; C ，这个函数把当前的值作为参数，此时我们可以对其做些附加操作(类型转换)并把它返回 (这一步类似于初始化操作)</p>
<h4 id="mergeValue"><a href="#mergeValue" class="headerlink" title="mergeValue"></a>mergeValue</h4><p>(C, V) =&gt; C，该函数把元素V合并到之前的元素C(createCombiner)上 (这个操作在每个分区内进行)</p>
<h4 id="mergeCombiners"><a href="#mergeCombiners" class="headerlink" title="mergeCombiners"></a>mergeCombiners</h4><p>(C, C) =&gt; C，该函数把2个元素C合并 (这个操作会跨分区间进行)</p>
<h3 id="衍生1-reduceByKey"><a href="#衍生1-reduceByKey" class="headerlink" title="衍生1 reduceByKey"></a>衍生1 reduceByKey</h3><p>同key的value合并，比如 rdd.reduceByKey(lambda x, y: x+y)<br>这个函数中的 createCombiner： lambda v: v；mergeValue，mergeCombiners 都是 func<br>好处：shuffe前就会combines,以及避免用groupByKey<br><img src="/2021/05/10/spark/rdd-reduceByKey.PNG" alt="rdd-reduceByKey"></p>
<h3 id="衍生2-groupByKey"><a href="#衍生2-groupByKey" class="headerlink" title="衍生2 groupByKey"></a>衍生2 groupByKey</h3><p>rdd中，按照key去 group 数据，组成一个序列。然后，在另一个rdd中按照key去做shuffle<br><img src="/2021/05/10/spark/rdd-groupByKey.PNG" alt="rdd-groupByKey"></p>
<h3 id="Spark中的MR效率"><a href="#Spark中的MR效率" class="headerlink" title="Spark中的MR效率"></a>Spark中的MR效率</h3><h4 id="transformation-的数量"><a href="#transformation-的数量" class="headerlink" title="transformation 的数量"></a>transformation 的数量</h4><p>每个transformation 都有rdd的lineary scan<br>eg:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rdd &#x3D; sc.parallelize(data) # data: (id, score) pairs</span><br><span class="line">•Bad design</span><br><span class="line">maxByKey &#x3D; rdd.combineByKey(…)</span><br><span class="line">sumByKey &#x3D; rdd.combineByKey(…)</span><br><span class="line">sumMaxRdd &#x3D; maxByKey.join(sumByKey)</span><br><span class="line"></span><br><span class="line">•Good design</span><br><span class="line">sumMaxRdd &#x3D; rdd.combineByKey(…)</span><br></pre></td></tr></table></figure>

<h4 id="transformation-的大小"><a href="#transformation-的大小" class="headerlink" title="transformation 的大小"></a>transformation 的大小</h4><p>越小，cost也就越小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rdd &#x3D; sc.parallelize(data) # data: (word, 1) pairs</span><br><span class="line">•Bad design</span><br><span class="line">countRdd &#x3D; rdd.reduceByKey(…)</span><br><span class="line">fileteredRdd &#x3D; countRdd.filter(…)</span><br><span class="line">•Good design</span><br><span class="line">fileteredRdd &#x3D; countRdd.filter(…)</span><br><span class="line">countRdd &#x3D; fileteredRdd.reduceByKey(…</span><br></pre></td></tr></table></figure>

<h4 id="shuffles"><a href="#shuffles" class="headerlink" title="shuffles"></a>shuffles</h4><p>尽量避免shuffle.性能的瓶颈，往往都在I/O和网络上，以及数据的序列化和反序列化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rdd &#x3D; sc.parallelize(data) # data: (word, 1) pairs</span><br><span class="line">•Bad design</span><br><span class="line">countRdd &#x3D; rdd.reduceByKey(…)</span><br><span class="line">fileteredRdd &#x3D; countRdd.filter(…)</span><br><span class="line">•Good design</span><br><span class="line">fileteredRdd &#x3D; countRdd.filter(…)</span><br><span class="line">countRdd &#x3D; fileteredRdd.reduceByKey(…)</span><br></pre></td></tr></table></figure>

<h3 id="如何合并两个RDD？"><a href="#如何合并两个RDD？" class="headerlink" title="如何合并两个RDD？"></a>如何合并两个RDD？</h3><h4 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h4><p>Concatenate two RDDs<br>How do A and B union together?<br>•What is the number of partitions for the union of A and B?<br>•Case 1: Different partitioner:<br>• Note: default partitioner is None<br>•Case 2: Same partitioner:   </p>
<h4 id="Zip"><a href="#Zip" class="headerlink" title="Zip"></a>Zip</h4><p>Pair two RDDs<br>Key-Value pairs after A.zip(B)<br>•Key: tuples in A<br>•Value: tuples in B<br>•Assumes that the two RDDs have<br>•The same number of partitions<br>•The same number of elements in each partition<br>•E.g., 1-to-1 map   </p>
<h4 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h4><p>Merge based on the keys from 2 RDDs,Just like join in DB<br>•join<br>•leftOuterJoin<br>•rightOuterJoin<br>•fullOuterJoin      </p>
<h1 id="Spark-优化"><a href="#Spark-优化" class="headerlink" title="Spark 优化"></a>Spark 优化</h1><h2 id="大小表join的优化"><a href="#大小表join的优化" class="headerlink" title="大小表join的优化"></a>大小表join的优化</h2><p>(<a target="_blank" rel="noopener" href="https://blog.csdn.net/wlk_328909605/article/details/82933552?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control&amp;dist_request_id=1619770363106_51540&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control%EF%BC%89">https://blog.csdn.net/wlk_328909605/article/details/82933552?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&amp;dist_request_id=1619770363106_51540&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control）</a></p>
<h3 id="小表对大表-broadcast-join"><a href="#小表对大表-broadcast-join" class="headerlink" title="小表对大表 broadcast  join"></a>小表对大表 broadcast  join</h3><p>广播小表，且被广播的表需要小于spark.sql.autoBroadcastJoinThreshold 所配置的值，默认是10M （或者加了 broadcast  join的hint。此外，基表不能被广播，比如leftouterjoin时，只能广播右表<br><img src="/2021/05/10/spark/boardcast-join.PNG" alt="boardcast-join">   </p>
<h3 id="Shuffle-Hash-Join"><a href="#Shuffle-Hash-Join" class="headerlink" title="Shuffle Hash Join"></a>Shuffle Hash Join</h3><p>以上 broadcast join 仅在小表时候高效，当表大的时候，使用broadcast会导致driver和executor端的压力。这里，我们可以通过partition的方式，来将大批量的数据分成小份的数据集并行计算。<br>利用同key相同，分区也相同的原理。对大表的join做分治： 也就是先将表划分成n个分区，再多两个表中相对应的数据进行hash join。   </p>
<h4 id="shuffle-hash-join的步骤"><a href="#shuffle-hash-join的步骤" class="headerlink" title="shuffle hash join的步骤:"></a>shuffle hash join的步骤:</h4><ul>
<li>对两张表按照join的keys，进行重分区。目的是为了让相同的key的记录分到对应的分区中</li>
<li>对对应分区中的数据进行join。这里会先将小表分区构造成一个hash表。然后根据大表分区中记录的join keys值拿出来进行匹配<h4 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h4></li>
</ul>
<ol>
<li>分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold所配置的值，默认是10M</li>
<li>基表不能被广播，比如left outer join时，只能广播右表</li>
<li>一侧的表要明显小于另外一侧，小的一侧将被广播（明显小于的定义为3倍小，此处为经验值）<br><img src="/2021/05/10/spark/Shuffle-Hash-Join.PNG" alt="Shuffle Hash Join"><h3 id="大表对大表-Sort-Merge-Join"><a href="#大表对大表-Sort-Merge-Join" class="headerlink" title="大表对大表 Sort Merge Join"></a>大表对大表 Sort Merge Join</h3>两个表，按照join keys进行重新的shuffle.来保证join keys值相同的记录会被分在对应的分区。分区后对每个分区内的数据进行排序。排序后再对对应的分区记录进行连接。<br>由于两个序列都是有序的，从头遍历。碰到相同key就输出。不同的key，左边小就用左边的。右边小就用右边的。（用完就丢）<br><img src="/2021/05/10/spark/Sort-Merge-Join.PNG" alt="Sort-Merge-Join"></li>
</ol>
<h2 id="Spark的结构调优"><a href="#Spark的结构调优" class="headerlink" title="Spark的结构调优"></a>Spark的结构调优</h2><ul>
<li>加内存  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark-shell –-driver-memory 8g </span><br><span class="line">spark-shell –-executor-memory 8g </span><br></pre></td></tr></table></figure>
<h3 id="Driver-调优"><a href="#Driver-调优" class="headerlink" title="Driver 调优"></a>Driver 调优</h3><h3 id="Executor-调优"><a href="#Executor-调优" class="headerlink" title="Executor 调优"></a>Executor 调优</h3><h3 id="Shuffle-的调优"><a href="#Shuffle-的调优" class="headerlink" title="Shuffle 的调优"></a>Shuffle 的调优</h3></li>
</ul>
<h2 id="spark-缓存-cache"><a href="#spark-缓存-cache" class="headerlink" title="spark 缓存(cache)"></a>spark 缓存(cache)</h2><p>(<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhuiqiuuuu/article/details/79290221">https://blog.csdn.net/zhuiqiuuuu/article/details/79290221</a>)</p>
<h3 id="RDD-缓存"><a href="#RDD-缓存" class="headerlink" title="RDD 缓存"></a>RDD 缓存</h3><p>Spark调优有个原则，就是对多次使用的rdd进行持久化。持久化的操作，只要用rdd.cache()或rdd.persist()<br>cache(): 使用非序列化的方式，将rdd的数据全部尝试持久化到内存中，cache是一个transformation算子，需要action来触发，才能真正的把rdd缓存到内存中。<br>persist(): 手动选择持久化级别，并用指定方式进行持久化。<br>缓存方式有以下：</p>
<ul>
<li>NONE :什么类型都不是</li>
<li>DISK_ONLY：磁盘</li>
<li>DISK_ONLY_2：磁盘；双副本</li>
<li>MEMORY_ONLY： 内存；反序列化；把RDD作为反序列化的方式存储，假如RDD的内容存不下，剩余的分区在以后需要时会重新计算，不会刷到磁盘上。</li>
<li>MEMORY_ONLY_2：内存；反序列化；双副本</li>
<li>MEMORY_ONLY_SER：内存；序列化；这种序列化方式，每一个partition以字节数据存储，好处是能带来更好的空间存储，但CPU耗费高</li>
<li>MEMORY_ONLY_SER_2 : 内存；序列化；双副本</li>
<li>MEMORY_AND_DISK：内存 + 磁盘；反序列化；双副本；RDD以反序列化的方式存内存，假如RDD的内容存不下，剩余的会存到磁盘</li>
<li>MEMORY_AND_DISK_2 : 内存 + 磁盘；反序列化；双副本</li>
<li>MEMORY_AND_DISK_SER：内存 + 磁盘；序列化  </li>
<li>MEMORY_AND_DISK_SER_2：内存 + 磁盘；序列化；双副本<h3 id="存储级别"><a href="#存储级别" class="headerlink" title="存储级别"></a>存储级别</h3>rdd在默认情况下满足的，就不需要更换。<br>假如MEMORY_ONLY不一定满足，可以使用MEMORY_ONLY_SER再加上一个序列化框架(kyro)。序列化就是为了节省空间。<br>不要写到磁盘，这样成本会变高，数据太大的时候，可以过滤一部分的数据再存。<h3 id="移除缓存"><a href="#移除缓存" class="headerlink" title="移除缓存"></a>移除缓存</h3>spark会自动地监控每个节点的使用情况，以一种LRU的机制（least-recently-used：最近很少使用）去自动移除。如果想手工代替这种自动去移除，可以使用RDD.unpersist()去处理</li>
</ul>
<h3 id="Dataframe-缓存"><a href="#Dataframe-缓存" class="headerlink" title="Dataframe 缓存"></a>Dataframe 缓存</h3><p>语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.cacheTable(&quot;...&quot;)</span><br><span class="line">dataFrame.cache()</span><br></pre></td></tr></table></figure>
<p>eg:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;缓存全表</span><br><span class="line">sqlContext.sql(&quot;CACHE TABLE activity&quot;)</span><br><span class="line">&#x2F;&#x2F;缓存过滤结果</span><br><span class="line">sqlContext.sql(&quot;CACHE TABLE activity_cached as select * from activity where ...&quot;)</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/08/hadoop-hdfs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ray">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/08/hadoop-hdfs/" class="post-title-link" itemprop="url">hadoop-hdfs</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-05-08 17:08:39 / Modified: 17:33:36" itemprop="dateCreated datePublished" datetime="2021-05-08T17:08:39+08:00">2021-05-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hadoop-and-HDFS"><a href="#Hadoop-and-HDFS" class="headerlink" title="Hadoop and HDFS"></a>Hadoop and HDFS</h1><h2 id="hadoop-特点"><a href="#hadoop-特点" class="headerlink" title="hadoop 特点"></a>hadoop 特点</h2><ul>
<li>存很大的数据</li>
<li>写一次，多次读取(不可修改，只可追加)</li>
<li>commodity and heterogenious hardware<h2 id="Hadoop-不适合："><a href="#Hadoop-不适合：" class="headerlink" title="Hadoop 不适合："></a>Hadoop 不适合：</h2></li>
<li>low-latency data access</li>
<li>大量小尺寸数据</li>
<li>multiple writers</li>
<li>arbitary file modification(文件经常会做变动)<h2 id="Hadoop-生态"><a href="#Hadoop-生态" class="headerlink" title="Hadoop 生态"></a>Hadoop 生态</h2><h3 id="Hadoop-核心"><a href="#Hadoop-核心" class="headerlink" title="Hadoop 核心"></a>Hadoop 核心</h3></li>
<li>HDFS</li>
<li>MapReduce</li>
<li>YARN<br>等等，像Pig, Hive,Spark, HBase<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3>HDFS 是一个 master-slave 的文件系统(file system).他可以分布式存储数据(存储在node，也就是machine上，通常，node都是 linux machine with java)。同样的，他也支持分布式计算，以及 horizontal scalability （Vertical Scaling vs. Horizontal Scaling ?）</li>
</ul>
<h3 id="HDFS-结构"><a href="#HDFS-结构" class="headerlink" title="HDFS 结构"></a>HDFS 结构</h3><p><img src="/2021/05/08/hadoop-hdfs/hdfs_architecture.PNG" alt="hdfs_architecture"></p>
<h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><ul>
<li>维护和管理 DataNodes 中的blocks,且 namenode 是 master node<h5 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h5></li>
<li>记录所有文件的元数据(metadata),matadata 是由 FsImage(filesystem namespace) 和 editlogs(all the recent modifications) 组成。</li>
<li>记录元数据中的每次变化</li>
<li>检测datanodes的状态</li>
<li>记录HDFS中blocks的所有记录</li>
<li>DataNode fails后的恢复工作   </li>
</ul>
<p>其中：<br>FsImage 文件用来记录数据块到文件的映射、目录或文件的结构、属性等信息，里面记录了自最后一次检查点之前 HDFS 文件系统中所有目录和文件的信息。   </p>
<p>Edit Log 文件记录了对文件的创建、删除、重命名等操作日志，也就是自最后一次检查点之后所有针对 HDFS 文件系统的操作都会记录在 Edit Log 文件中。例如，在 HDFS 中创建一个文件， NameNode 就会在 Edit Log 中插入一条记录，同样修改文件的副本系数也会在 Edit Log 中插入一条记录。<br>注意，NameNode daemon（守护程序）需要一直跑，一旦namenode down, 集群(cluster) 也会down.</p>
<p>简单说:<br>metadata: fs images + edit log/ written in memory<br>fs image = paths + block ids + user + group + permissions/ written in disk<br>edit log = operations/ written in disk  </p>
<!-- ![namenode](namenode.PNG) -->

<h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><p>真正存数据的地方,可以用来performs 读写request，以及报告状态给NameNode(heartbeat)，属于slave-node </p>
<p>当nameNode failed, 集群就会down,没有namenode中的metadata，就无法重组blocks,为了防止这样的情况，我们加上Secondary NameNode</p>
<h4 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h4><p>取Namenode中的metadata中的checkpoints. Secondary NameNode不是namenode的备份，且必须再另一个node上跑</p>
<h5 id="Secondary-NameNode-作用"><a href="#Secondary-NameNode-作用" class="headerlink" title="Secondary NameNode 作用"></a>Secondary NameNode 作用</h5><ul>
<li>performs memory intensive housekeeping   </li>
<li>存储Fsimage 和 editlogs的备份</li>
<li>周期性的把editlogs的改动应用到fsimages上，并刷新自身的editlogs</li>
<li>一旦namenode down,file system metadata就可以从secondary namenode上的最新的fsimage上恢复<h5 id="Secondary-NameNode-的工作机制"><a href="#Secondary-NameNode-的工作机制" class="headerlink" title="Secondary NameNode 的工作机制"></a>Secondary NameNode 的工作机制</h5><img src="/2021/05/08/hadoop-hdfs/Secondary_Namenode.PNG" alt="Secondary_Namenode"><br>详细解释：<br>(<a target="_blank" rel="noopener" href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3082">https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3082</a>)</li>
</ul>
<h3 id="hdfs-读写过程"><a href="#hdfs-读写过程" class="headerlink" title="hdfs 读写过程"></a>hdfs 读写过程</h3><h4 id="hdfs-read"><a href="#hdfs-read" class="headerlink" title="hdfs read"></a>hdfs read</h4><p><img src="/2021/05/08/hadoop-hdfs/hdfs_read.PNG" alt="hdfs_read"></p>
<h4 id="hdfs-write"><a href="#hdfs-write" class="headerlink" title="hdfs write"></a>hdfs write</h4><p><img src="/2021/05/08/hadoop-hdfs/hdfs_write.PNG" alt="hdfs_write"><br><a target="_blank" rel="noopener" href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3082">https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3082</a></p>
<h2 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS - HA"></a>HDFS - HA</h2><p>HA 模式下，会有两个namenode。 其中只有一个namenode处于active的状态，另一个处于standby状态。这种机制实现namenode的双机热备高可用功能。</p>
<h3 id="StandBy-Namenode-HA"><a href="#StandBy-Namenode-HA" class="headerlink" title="StandBy Namenode - HA"></a>StandBy Namenode - HA</h3><p>standby namenode 会时刻同步active namenode的元数据。一旦active的namenode down,standby 会自动或者手动变为active的状态。自动切换的实现，可以通过zookeeper的仲裁来实现(kafka集群结构也同样依赖zookeeper)。zookeeper会检测两个namenode的状态，来选举active的namenode.此外，active 和 standby 的同步，是通过journal nodes来实现的。 </p>
<h3 id="HA-下的结构"><a href="#HA-下的结构" class="headerlink" title="HA 下的结构"></a>HA 下的结构</h3><p><img src="/2021/05/08/hadoop-hdfs/HA.PNG" alt="HA"><br>机制：（<a target="_blank" rel="noopener" href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3079%EF%BC%89">https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3079）</a><br>（ha下，active namenode 和 standby 必须有一样的metadata）    </p>
<p>ZooKeeper（ZK）集群作为一个高可靠系统，能够为集群协作数据提供监控，并将数据的更改随时反馈给客户端。HDFS 的热备功能依赖 ZK 提供的两个特性：错误监测、活动节点选举。HDFS 通过 ZK 实现高可用的机制如下。</p>
<p>每个 NameNode 都会在 ZK 中注册并且持久化一个 session 标识，一旦 NameNode 失效了，那么 session 也将过期，而 ZK 也会通知其他的 NameNode 发起一个失败切换。ZK 提供了一个简单的机制来保证只有一个 NameNode 是活动的，那就是独占锁，如果当前的活动 NameNode 失效了，那么另一个 NameNode 将获取 ZK 中的独占锁，表明自己是活动的节点。</p>
<p>ZKFailoverController（ZKFC）是 ZK 集群的客户端，用来监控 NN 的状态信息，每个运行 NameNode 的节点必须要运行一个 ZKFC。ZKFC 提供以下功能：</p>
<ul>
<li>健康检查，ZKFC 定期对本地的 NN 发起 health-check 的命令，如果 NN 正确返回，那么 NN 被认为是 OK 的，否则被认为是失效节点；</li>
<li>session管理，当本地 NN 是健康的时候，ZKFC 将会在 ZK 中持有一个 session，如果本地 NN 又正好是 Active，那么 ZKFC 将持有一个短暂的节点作为锁，一旦本地 NN 失效了，那么这个节点就会被自动删除；</li>
<li>基础选举，如果本地 NN 是健康的，并且 ZKFC 发现没有其他 NN 持有这个独占锁，那么它将试图去获取该锁，一旦成功，那么它就开始执行 Failover，然后变成 Active 状态的 NN 节点；Failover 的过程分两步，首先对之前的 NameNode 执行隔离（如果需要的话），然后将本地 NameNode 切换到 Active 状态。</li>
</ul>
<h3 id="HA-Quorum-Jouranl-Nodes"><a href="#HA-Quorum-Jouranl-Nodes" class="headerlink" title="HA - Quorum Jouranl Nodes"></a>HA - Quorum Jouranl Nodes</h3><p>quorum jouranl nodes，其实就是JournalNode集群。这里用来同步两个namenode中的元数据，同步方式如图↓<br><img src="/2021/05/08/hadoop-hdfs/jn.PNG" alt="jn"><br>JournalNode 集群可以几乎实时的去 NameNode 上拉取元数据，然后保存元数据到 JournalNode 集群；同时，处于 standby 状态的 NameNode 也会实时的去 JournalNode 集群上同步 JNS 数据，通过这种方式，就实现了两个 NameNode 之间的数据同步。</p>
<p>那么，JournalNode 集群内部是如何实现的呢？</p>
<p>两个 NameNode 为了数据同步，会通过一组称作 JournalNodes 的独立进程进行相互通信。当 Active 状态的 NameNode 元数据有任何修改时，会告知大部分的 JournalNodes 进程。同时，Standby 状态的 NameNode 也会读取 JNs 中的变更信息，并且一直监控 EditLog （事务日志）的变化，并把变化应用于自己的命名空间。Standby 可以确保在集群出错时，元数据状态已经完全同步了。<br><img src="/2021/05/08/hadoop-hdfs/qjm.PNG" alt="qjm"></p>
<p>jn的集群机制： (<a target="_blank" rel="noopener" href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3079">https://kaiwu.lagou.com/course/courseInfo.htm?courseId=144#/detail/pc?id=3079</a>)</p>
<h3 id="HA-共享存储-shared-storage"><a href="#HA-共享存储-shared-storage" class="headerlink" title="HA - 共享存储(shared storage)"></a>HA - 共享存储(shared storage)</h3><p><img src="/2021/05/08/hadoop-hdfs/ha-share-storage.PNG" alt="ha-share-storage"><br>The StandbyNode and the active NameNode keep in sync with each other by using a shared storage device. The active NameNode logs the record of any modification done in its namespace to an EditLog present in this shared storage. The StandbyNode reads the changes made to the EditLogs in this shared storage and applies it to its own namespace.<br>Now, in case of failover, the StandbyNode updates its metadata information using the EditLogs in the shared storage at first. Then, it takes the responsibility of the Active NameNode. This makes the current namespace state synchronized with the state before failover.<br>The administrator must configure at least one fencing method to avoid a split-brain scenario.<br>The system may employ a range of fencing mechanisms. It may include killing of the NameNode’s process and revoking its access to the shared storage directory.<br>As a last resort, we can fence the previously active NameNode with a technique known as STONITH, or “shoot the other node in the head”. STONITH uses a specialized power distribution unit to forcibly power down the NameNode machine。（待整合）</p>
<h2 id="HDFS中的概念"><a href="#HDFS中的概念" class="headerlink" title="HDFS中的概念"></a>HDFS中的概念</h2><h3 id="checkpointing"><a href="#checkpointing" class="headerlink" title="checkpointing"></a>checkpointing</h3><p><img src="/2021/05/08/hadoop-hdfs/checkpoints.PNG" alt="checkpoints"></p>
<h3 id="Data-locality"><a href="#Data-locality" class="headerlink" title="Data locality"></a>Data locality</h3><p><img src="/2021/05/08/hadoop-hdfs/Data_locality.PNG" alt="Data_locality"></p>
<h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p><img src="/2021/05/08/hadoop-hdfs/replication.PNG" alt="replication"></p>
<h3 id="Rack-awareness"><a href="#Rack-awareness" class="headerlink" title="Rack awareness"></a>Rack awareness</h3><p><img src="/2021/05/08/hadoop-hdfs/Rack_awareness.PNG" alt="Rack-awareness"></p>
<h4 id="Why-Rack-awareness"><a href="#Why-Rack-awareness" class="headerlink" title="Why Rack awareness"></a>Why Rack awareness</h4><ul>
<li>减少延迟</li>
</ul>
<ol>
<li>读：blocks from multiple racks</li>
<li>写：to 2 racks instead of 3 per block</li>
</ol>
<ul>
<li>容错<br>Never put your eggs in the same basket<br><img src="/2021/05/08/hadoop-hdfs/yra.PNG" alt="yra"> </li>
</ul>
<h2 id="Small-file-problem"><a href="#Small-file-problem" class="headerlink" title="Small file problem"></a>Small file problem</h2><p>特别小的文件仍然会占用128kb block。这样会造成浪费</p>
<!-- 
## HDFS 的 access,cli 以及debug
### Access 
cli： hadoop cli
gui: ambari,hue
api: java,c, web rest

### Cli:
##### DFS
##### DFSADMIN
##### Balance
##### FSCK

### HDFS debug -->

<h2 id="常见数据格式"><a href="#常见数据格式" class="headerlink" title="常见数据格式"></a>常见数据格式</h2><table>
<thead>
<tr>
<th>Format</th>
<th>feature</th>
<th>for writes</th>
<th>for reads</th>
</tr>
</thead>
<tbody><tr>
<td>Text</td>
<td>JSON, CSV, XML, TEXT <br>Data is stored in bulky way<br> Not efficient for querying and analytics <br>Limited compression capabilities</td>
<td>Fast, but inefficient for storage</td>
<td>Easy to read and parse; Slow for reads</td>
</tr>
<tr>
<td>Sequence</td>
<td>Provides persistent data structure for binary key-value pairs<br>Row-based<br>Commonly used to transfer Hadoop MR-jobs<br>Can be used as archive to pack small files<br>Not efficient for querying and analytics<br>Limited compression capabilities<br>Support splitting even when data is compressed<br></td>
<td>Useful when data needs to be shared between MR job</td>
<td>Easy to read and parse</td>
</tr>
<tr>
<td>PARQUET</td>
<td>Column-oriented binary file format <br>Uses record shredding and assembly algorithm <br>Each data file contains the values for a set of rows<br>Efficient for I/O in case specific columns needs to be queried<br>Schema is moved to the footer<br>Integrated compression and indexes</td>
<td>Additional parsing needs to be done</td>
<td>Easy to read and parse<br>Efficient when columns needs to be queried<br>Useful in scenarios when schema evolving by adding columns<br></td>
</tr>
<tr>
<td>AVRO</td>
<td>Widely used as a serialization platform<br>Row-based<br>Offers compact and fast compression format<br>Schema is stored in the file, but is segregated from data<br>Splittable<br>Support schema evolution<br></td>
<td>Works as serialization framework, handle schema evolution</td>
<td>Easy to read and parse</td>
</tr>
<tr>
<td>ORC</td>
<td>Considered evolution of RCFile<br>Stores collection of rows within the collection<br>The row data is stored in columnar format<br>Introduces a lightweight indexing that enables skipping of irrelevant blocks of rows<br>Splittable: allow parallel processing of row collections<br>It comes with basic statistics for columns<br>Schema is segregated into footer<br></td>
<td>Additional parsing needs to be done</td>
<td>Easy to read and parse<br>Efficient when columns needs to be queried</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/29/Hadoop-%E7%AE%80%E4%BB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ray">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/29/Hadoop-%E7%AE%80%E4%BB%8B/" class="post-title-link" itemprop="url">Hadoop 简介</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-29 17:47:13" itemprop="dateCreated datePublished" datetime="2021-04-29T17:47:13+08:00">2021-04-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-30 12:10:45" itemprop="dateModified" datetime="2021-04-30T12:10:45+08:00">2021-04-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Hadoop-what"><a href="#Hadoop-what" class="headerlink" title="Hadoop, what?"></a>Hadoop, what?</h2><p>Hadoop 是一个分布式系统基础架构。这篇聊聊他的进化历史，从1.0 到 2.0 </p>
<h2 id="Hadoop-1-0"><a href="#Hadoop-1-0" class="headerlink" title="Hadoop 1.0"></a>Hadoop 1.0</h2><p>Hadoop 1.0 是最早hadoop的版本，主要由两个部分构成，HDFS(存储) + MapReduce(计算)</p>
<h3 id="HDFS-（存储）"><a href="#HDFS-（存储）" class="headerlink" title="HDFS （存储）"></a>HDFS （存储）</h3><p>hdfs,全称是hadoop distribute file system,如名字所言: 分布式(Distribute)，文件系统(file system)。就是以分布式的形式存储文件。所谓分布式存储，就是将文件分割成若干个小文件，并分散存储在不同服务器上。不过现在大家都用云存储了，hdfs主要是入门基础。不用太深，图一乐。<br>HDFS 的结构主要由 NameNode(metadata) + DataNode(data) 组成。<br>NameNode 是存储元数据的节点，元数据指的是文件的block位置，size 等。 DataNode 是真正存储数据的位置，通常，一个数据会被分割成几分，且每一份数据会复制3份(为什么是3份)来保证数据不会被丢失。在1.0的版本中，namenode同样负责job的调度，等等，这些都在2.0里丢给了yarn。</p>
<h3 id="MapReduce（计算）"><a href="#MapReduce（计算）" class="headerlink" title="MapReduce（计算）"></a>MapReduce（计算）</h3><p>在hadoop生态里，最早的是mapreduce,再往后，就是spark，以及tez。<br>MapReduce 是一种计算框架。字面意思，就是把计算分为map 和 reduce。 map中，通常是数据的转换。而reduce，更多的是聚合。比如，现在统计一组数据中男生，女生的个数，处理逻辑如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">name1 -&gt; man -&gt; 1</span><br><span class="line">name2 -&gt; women -&gt; 1</span><br><span class="line">name3 -&gt; man -&gt; 1</span><br><span class="line">name4 -&gt; women -&gt; 1</span><br></pre></td></tr></table></figure>
<p>在这一步，就是map的过程，而将这一步统计在一起</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">man -&gt; 2</span><br><span class="line">women -&gt; 2</span><br></pre></td></tr></table></figure>
<p>这就属于reduce的过程。而这种计算过程，也对分布式计算非常友好。因此，在最开始的hadoop 1.0 中，结构就是<br>mapreduce(计算) + hdfs（存储）</p>
<h3 id="Hadoop-1-0的缺点"><a href="#Hadoop-1-0的缺点" class="headerlink" title="Hadoop 1.0的缺点"></a>Hadoop 1.0的缺点</h3><p>最早开始，hadoop 是 mapreduce + hdfs，已经没人用了。一是这样的计算方式，在极大数据的时候，中间的缓存太大。此外，由于最开始，hadoop的调度方式是顺序结构。也就是FIFO，导致了整个计算过程非常缓慢。而且，整个系统没有热备份(也就是实时备份)，已经无法适应大规模计算了，所以1.0的结构已经被彻底抛弃。</p>
<h2 id="Hadoop-2-0"><a href="#Hadoop-2-0" class="headerlink" title="Hadoop 2.0"></a>Hadoop 2.0</h2><p>Hadoop 2.0的时候，整个结构变成了 mapreduce(计算) + yarn(资源管理) + hdfs(存储)。此外，在2.0的时候已经支持了spark的计算框架。并且，新加入了HA(high available)模式. </p>
<h3 id="YARN-是什么"><a href="#YARN-是什么" class="headerlink" title="YARN 是什么"></a>YARN 是什么</h3><p>YARN 的全称是 Yet Another Resource Negotiator. YARN 主要管理两个资源：CPU + Memory, 并且他的结构如下图：<br><img src="/2021/04/29/Hadoop-%E7%AE%80%E4%BB%8B/1_yarn.png" alt="yarn"><br>其中，资源管理是由 RM(ResourceManager) + AM(ApplicationMaster) + NM(NodeManager) 组成,如上图所示。<br>从图中我们可以看出，yarn是典型的master-slave结构。其中，RM对所有的资源进行调度和管理，而NM会对自己的资源做出隔离和管理。连接NM和RM的就是AM，AM会负责向RM申请资源，并对container中的Aplication进行跟踪和管理。</p>
<h4 id="YARN-启动一个作业的流程"><a href="#YARN-启动一个作业的流程" class="headerlink" title="YARN 启动一个作业的流程"></a>YARN 启动一个作业的流程</h4><p><img src="/2021/04/29/Hadoop-%E7%AE%80%E4%BB%8B/1_yarn_work.png" alt="1_yarn_work">   </p>
<ol>
<li><p>首先，client 向 RM 提交 application</p>
</li>
<li><p>RM 收到后，会让 NM 启动一个container,同时，也会为这个NM启动一个AM。</p>
</li>
<li><p>AM 向 RM 注册。</p>
</li>
<li><p>AM 用轮询的方式向 RM 中的 resource scheduler要资源</p>
</li>
<li><p>AM 在拿到资源后，会联系 NM，请求启动计算任务</p>
</li>
<li><p>NM 会根据 AM 拿到的资源，在 container 中启动任务</p>
</li>
<li><p>任务会向 AM 汇报自己的 状态 和 进度，以便让AM掌握各个任务的执行状况</p>
</li>
<li><p>任务做完之后，AM 会向 RM 提交注销，并关闭自己</p>
<h4 id="YARN-的调度方式"><a href="#YARN-的调度方式" class="headerlink" title="YARN 的调度方式"></a>YARN 的调度方式</h4><p>从宏观上来说，调度方式又如下三种: 集中式调度器(Monolithic scheduler)，双层调度器(Two-Level Scheduler)，状态共享调度器(Shared-State Scheduler)</p>
</li>
<li><p>集中式调度器(Monolithic scheduler)<br>集中式调度器只有一个中央调度器构成。其中，所有的计算资源申请，调度逻辑都会交给中央调度器。这也就直接导致了中央调度器再做高并发的情况下，会出现性能瓶颈。假如此时，有多个资源申请，中央调度器只能顺序执行</p>
</li>
<li><p>双层调度器(Two-Level Scheduler)<br>双层调度器(Two-Level Scheduler) 在 集中式 基础上，变为了 中央调度器 + 框架调度器。此时，中央调度器只负责资源的状态，然后按照一定的策略（FIFO, Fair, Capacity, Dominant Resouce Fair）把资源分配给 框架调度器，框架调度器在根据接收到的资源来给容器分配任务。 </p>
</li>
<li><p>状态共享调度器（Shared-State Scheduler）<br>状态共享调度器（Shared-State Scheduler，结构同样是 中央调度器 + 框架调度器。但，此时的 中央调度器 只负责保存集群的使用信息，不再去分配资源。而 框架调度器 会根据当前集群的使用信息来去申请资源。一旦 框架调度器 申请完资源，新的资源会更新中央调度器的信息。资源申请若是出现了竞争，会通过 事务 进行，来保证操作的原子性（见数据库中的事务）。这种类似 MVCC的乐观并发机制。缺点是调度公平性不足。</p>
</li>
</ol>
<p>那么，Yarn是什么<br>Yarn 很像 双层调度器 的结构，但是有一些区别：双层调度的模式是 框架调度器主动的向 中央调度器申请资源，而 Yarn中，资源是由中央(RM) 分配给地方（NM）。不过整体的结构相似。</p>
<h3 id="Hadoop-中的-HA-mode"><a href="#Hadoop-中的-HA-mode" class="headerlink" title="Hadoop 中的 HA mode"></a>Hadoop 中的 HA mode</h3><p>HA,也就是 High available。一般的hadoop system,结构是由 namenode + datanode组成。 但是，假如，namenode 故障了，整个集群就会无法启动，直到你重启了namenode。那这个时候，HA模式就可以解决这个问题，HA模式在 namenode + datanode 基础上，变成了 namenode（active） + namenode (standby) + datanode. 其中，namenode（active）仍然负责所有的操作，而 namenode (standby) 是作为备份。其中 namenode（active） 和 namenode (standby)为了保证数据一致，会通过一个共享存储系统，比如 zookeeper，来保证一致性。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ray</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ray</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
